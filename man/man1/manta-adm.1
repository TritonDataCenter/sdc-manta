.TH MANTA\-ADM 1 "2019" Manta "Manta Operator Commands"
.SH NAME
.PP
manta\-adm \- administer a Manta deployment
.SH SYNOPSIS
.PP
\fB\fCmanta\-adm alarm SUBCOMMAND... [OPTIONS...]\fR
.PP
\fB\fCmanta\-adm cn [\-l LOG_FILE] [\-H] [\-o FIELD...] [\-n] [\-s] CN_FILTER\fR
.PP
\fB\fCmanta\-adm gc SUBCOMMAND... [OPTIONS...]\fR
.PP
\fB\fCmanta\-adm genconfig "lab" | "coal"\fR
.PP
\fB\fCmanta\-adm genconfig [\-\-directory=DIR] \-\-from\-file=FILE\fR
.PP
\fB\fCmanta\-adm show [\-l LOG_FILE] [\-a] [\-c] [\-H] [\-o FIELD...] [\-s] SERVICE\fR
.PP
\fB\fCmanta\-adm show [\-l LOG_FILE] [\-js] SERVICE\fR
.PP
\fB\fCmanta\-adm update [\-l LOG_FILE] [\-n] [\-y] [\-\-no\-reprovision] [\-\-skip\-verify\-channel] FILE [SERVICE]\fR
.PP
\fB\fCmanta\-adm zk list [\-l LOG_FILE] [\-H] [\-o FIELD...]\fR
.PP
\fB\fCmanta\-adm zk fixup [\-l LOG_FILE] [\-n] [\-y]\fR
.SH DESCRIPTION
.PP
The \fB\fCmanta\-adm\fR command is used to administer various aspects of a Manta
deployment.  This command only operates on zones within the same datacenter.
The command may need to be repeated in other datacenters in order to execute it
across an entire Manta deployment.
.TP
\fB\fCmanta\-adm alarm\fR
List and configure amon\-based alarms for Manta.
.TP
\fB\fCmanta\-adm cn\fR
Show information about Manta servers in this DC.
.TP
\fB\fCmanta\-adm gc\fR
Administer garbage\-collector zones.
.TP
\fB\fCmanta\-adm genconfig\fR
Generate a configuration for a COAL, lab, or multi\-server deployment.
.TP
\fB\fCmanta\-adm show\fR
Show information about deployed services.
.TP
\fB\fCmanta\-adm update\fR
Update deployment to match a JSON configuration.
.TP
\fB\fCmanta\-adm zk\fR
View and modify ZooKeeper servers configuration.
.PP
With the exception of agents (which are not currently managed by this tool),
Manta components are deployed as SDC \fBzones\fP (also called \fBinstances\fP).
Each zone is part of a \fBservice\fP, which identifies its role in the system.
.PP
Services that are part of the Manta application include:
.TP
\fBauthcache\fP
Stores user identity information
.TP
\fBboray\fP
PostgreSQL interface for manta buckets system
.TP
\fBbuckets\-postgres\fP
PostgreSQL databases used for storing object metadata for the buckets system
.TP
\fBbuckets\-api\fP
Handles end user buckets API requests
.TP
\fBelectric\-boray\fP
Boray proxy for buckets that handles sharding using consistent hashing
.TP
\fBelectric\-moray\fP
Moray proxy that handles sharding using consistent hashing
.TP
\fBgarbage\-collector\fP
Processes delete records in specialized Postgres tables
.TP
\fBloadbalancer\fP
Handles SSL termination and loadbalancing for "webapi"
.TP
\fBmadtom\fP
Operational dashboard for component health
.TP
\fBmoray\fP
Key\-value store used to access PostgreSQL
.TP
\fBnameservice\fP
internal DNS nameservers and ZooKeeper nodes
.TP
\fBops\fP
Manages asynchronous operations like garbage collection, metering, and auditing
.TP
\fBpostgres\fP
PostgreSQL databases used for storing object metadata
.TP
\fBpgstatsmon\fP
Monitoring system for Postgres
.TP
\fBprometheus\fP
Time\-series database that aggregates Manta and Triton metrics
.TP
\fBreshard\fP
Automated resharding system for Manta
.TP
\fBstorage\fP
Stores actual object data
.TP
\fBwebapi\fP
Handles end user API requests
.PP
These services are described in much more detail in the Manta Operator's Guide.
.PP
The SDC SAPI service stores configuration about the "manta" application, each of
the above services, and each instance of the above service.  The information
reported by this tool is derived from SDC's internal APIs, including SAPI (for
service configuration), CNAPI (for compute node information), VMAPI (for zone
information), NAPI (for network information), and IMGAPI (for image information)
services.
.PP
Many subcommands produce tabular output, with a header row, one data record per
line, and columns separated by whitespace.  With any of these commands, you can
use options:
.TP
\fB\fC\-H, \-\-omit\-header\fR
Do not print the header row.
.TP
\fB\fC\-o, \-\-columns FIELD[,FIELD...]\fR
Only print columns named \fB\fCFIELD\fR\&.  You can specify this option multiple times
or use comma\-separated field names (or both) to select multiple fields.  The
available field names vary by command and are described in the corresponding
command section above.  In general, the default set of field names for each
command is subject to change at any time.
.PP
Many commands also accept:
.TP
\fB\fC\-l, \-\-log_file LOGFILE\fR
Emit verbose log to LOGFILE.  The special string "stdout" causes output to be
emitted to the program's stdout.
.PP
Commands that make changes support:
.TP
\fB\fC\-n, \-\-dryrun\fR
Print what changes would be made without actually making them.
.TP
\fB\fC\-y, \-\-confirm\fR
Bypass all confirmation prompts.
.PP
\fBImportant note for programmatic users:\fP Except as noted below, the output
format for this command is subject to change at any time. The only subcommands
whose output is considered committed are:
.RS
.IP \(bu 2
\fB\fCmanta\-adm cn\fR, only when used with the "\-o" option
.IP \(bu 2
\fB\fCmanta\-adm show\fR, only when used with either the "\-o" or "\-j" option
.IP \(bu 2
\fB\fCmanta\-adm zk list\fR, only when used with the "\-o" option
.RE
.PP
The output for any other commands may change at any time.  The \fB\fCmanta\-adm alarm\fR
subcommand is still considered an experimental interface.  All other documented
subcommands, options, and arguments are committed, and you can use the exit
status of the program to determine success or failure.
.SH SUBCOMMANDS
.SS "gc" subcommand
.PP
\fB\fCmanta\-adm gc show [\-j]\fR
.PP
\fB\fCmanta\-adm gc update CONFIG_FILE\fR
.PP
\fB\fCmanta\-adm gc gen\-shard\-assignment\fR
.PP
\fB\fCmanta\-adm gc genconfig [\-m MAX_CNS] [\-a SERVICE...] [\-i] IMAGE_UUID NCOLLECTORS\fR
.PP
Garbage collection is the process that cleans up files on storage zones that are
no longer referenced in the metadata tier.
.PP
The \fB\fCmanta\-adm gc\fR subcommand provides tools that allow operators:
.RS
.IP \(bu 2
generate a configuration for deploying garbage\-collector instances
.IP \(bu 2
manage the assignment of metadata shards to garbage\-collector instances
.RE
.PP
\fB\fCmanta\-adm gc show \-j\fR
.PP
Dump a mapping that shows which shards are assigned to which garbage\-collectors.
The output of this command can be re\-purposed as input to \fB\fCmanta\-adm
gc update\fR\&. The interaction between these commands is similar to that
between \fB\fCmanta\-adm show\fR and \fB\fCmanta\-adm update\fR\&.
.PP
\fB\fCmanta\-adm gc update CONFIG_FILE\fR
.PP
Update the mapping from shards to garbage\-collectors. This will require restarting
the garbage\-collectors so that they pick up the new assigned shards. CONFIG_FILE
here should have the same format as the output of \fB\fCmanta\-adm gc show \-j\fR\&.
.PP
\fB\fCmanta\-adm gc genconfig [\-m MAX_CNS] [\-a SERVICE...] [\-i] IMAGE_UUID NCOLLECTORS\fR
.PP
Generate a service deployment layout (interpretable by manta\-adm update) by
layering NCOLLECTORS garbage\-collector zones onto the existing deployment
layout in a minimally disruptive fashion. By default, this means the command
will:
.RS
.IP \(bu 2
avoid colocating garbage\-collector zones with loadbalancer or nameservice
zones.
.IP \(bu 2
add garbage\-collectors to at most MAX_CNS CNs meeting the previous criterion
if specified, otherwise use as many CNs meeting the above criterion as are
available.
.IP \(bu 2
distribute garbage\-collectors as evenly as possible amongest the CNs between
the above criteria.
.RE
.PP
In some deployments these criteria cannot be met. To generate a layout that
does not meet the criteria pass the \-i flag. The flag should not be used in
production deployments.
.PP
To change the list of services to avoid, pass multiple SERVICEs in a
comma\-separated list or with repeated \-a flags.
.PP
\fB\fCmanta\-adm gc gen\-shard\-assignment\fR
.PP
Generate a mapping from shards to garbage\-collectors based on SAPI metadata that
distributes index shards to garbage\-collectors as evenly as possible.
.SS "alarm" subcommand
.PP
\fB\fCmanta\-adm alarm close ALARM_ID...\fR
.PP
\fB\fCmanta\-adm alarm config probegroup list [\-H] [\-o FIELD...]\fR
.PP
\fB\fCmanta\-adm alarm config show\fR
.PP
\fB\fCmanta\-adm alarm config update [\-n] [\-y] [\-\-unconfigure]\fR
.PP
\fB\fCmanta\-adm alarm config verify [\-\-unconfigure]\fR
.PP
\fB\fCmanta\-adm alarm details ALARM_ID...\fR
.PP
\fB\fCmanta\-adm alarm faults ALARM_ID...\fR
.PP
\fB\fCmanta\-adm alarm list [\-H] [\-o FIELD...] [\-\-state=STATE]\fR
.PP
\fB\fCmanta\-adm alarm maint create CREATE_OPTIONS\fR
.PP
\fB\fCmanta\-adm alarm maint delete WIN_ID...\fR
.PP
\fB\fCmanta\-adm alarm maint list [\-H] [\-o FIELD...]\fR
.PP
\fB\fCmanta\-adm alarm maint show\fR
.PP
\fB\fCmanta\-adm alarm metadata events\fR
.PP
\fB\fCmanta\-adm alarm metadata ka [EVENT_NAME...]\fR
.PP
\fB\fCmanta\-adm alarm notify on|off ALARM_ID...\fR
.PP
\fB\fCmanta\-adm alarm show\fR
.PP
The \fB\fCmanta\-adm alarm\fR subcommand provides several tools that allow operators to:
.RS
.IP \(bu 2
view and configure amon probes and probe groups (\fB\fCconfig\fR subcommand)
.IP \(bu 2
view open alarms (\fB\fCshow\fR, \fB\fClist\fR, \fB\fCdetails\fR, and \fB\fCfaults\fR subcommands)
.IP \(bu 2
configure notifications for open alarms (\fB\fCnotify\fR subcommand)
.IP \(bu 2
view local metadata about alarms and probes (\fB\fCmetadata\fR subcommand)
.IP \(bu 2
view and configure amon maintenance windows (\fB\fCmaint\fR subcommand)
.RE
.PP
The primary commands for working with alarms are:
.RS
.IP \(bu 2
\fB\fCmanta\-adm alarm config update\fR: typically used during initial deployment and
after other deployment operations to ensure that the right set of probes and
probe groups are configured for the deployed components
.IP \(bu 2
\fB\fCmanta\-adm alarm show\fR: summarize open alarms
.IP \(bu 2
\fB\fCmanta\-adm alarm details ALARM_ID...\fR: report detailed information (including
suggested actions) for the specified alarms
.IP \(bu 2
\fB\fCmanta\-adm alarm close ALARM_ID...\fR: close open alarms, indicating that they
no longer represent issues
.RE
.PP
For background about Amon itself, probes, probegroups, and alarms, see the
Triton Amon reference documentation.
.PP
As with other subcommands, this command only operates on the current Triton
datacenter.  In multi\-datacenter deployments, alarms are managed separately in
each datacenter.
.PP
Some of the following subcommands can operate on many alarms.  These subcommands
exit failure if they fail for any of the specified alarms, but the operation may
have completed successfully for other alarms.  For example, closing 3 alarms is
not atomic.  If the operation fails, then 1, 2, or 3 alarms may still be open.
.PP
\fB\fCmanta\-adm alarm close ALARM_ID...\fR
.PP
Close the specified alarms.  These alarms will no longer show up in the
\fB\fCmanta\-adm alarm list\fR or \fB\fCmanta\-adm alarm show\fR output.  Amon purges closed
alarms completely after some period of time.
.PP
If the underlying issue that caused an alarm is not actually resolved, then a
new alarm may be opened for the same issue.  In some cases, that can happen
almost immediately.  In other cases, it may take many hours for the problem to
resurface.  In the case of transient issues, a new alarm may not open again
until the issue occurs again, which could be days, weeks, or months later.  That
does not mean the underlying issue was actually resolved.
.PP
As mentioned above, this command attempts to separately close each of the
specified alarms.  It's possible for some of the specified alarms to be closed
even if others were not.
.PP
\fB\fCmanta\-adm alarm config probegroup list [\-H] [\-o FIELD...]\fR
.PP
List configured probe groups in tabular form.  This is primarily useful in
debugging unexpected behavior from the alarms themselves.  The \fB\fCmanta\-adm alarm
config show\fR command provides a more useful summary of the probe groups that are
configured.
.PP
\fB\fCmanta\-adm alarm config show\fR
.PP
Shows summary information about the probes and probe groups that are configured.
This is not generally necessary but it can be useful to verify that probes are
configured as expected.
.PP
\fB\fCmanta\-adm alarm config update [\-n] [\-y] [\-\-unconfigure]\fR
.PP
Examines the Manta components that are deployed and the alarm configuration
(specifically, the probes and probe groups deployed to monitor those components)
and compares them with the expected configuration.  If these do not match,
prints out a summary of proposed changes to the configuration and optionally
applies those changes.
.PP
If \fB\fC\-\-unconfigure\fR is specified, then the tool removes all probes and probe
groups.
.PP
This is the primary tool for updating the set of deployed probes and probe
groups.  Operators would typically use this command:
.RS
.IP \(bu 2
during initial deployment to deploy probes and probe groups
.IP \(bu 2
after deploying (or undeploying) any Manta components to deploy (or remove)
probes related to the affected components
.IP \(bu 2
after updating the \fB\fCmanta\-adm\fR tool itself, which bundles the probe
definitions, to deploy any new or updated probes
.IP \(bu 2
at any time to verify that the configuration matches what's expected
.RE
.PP
This operation is idempotent.
.PP
This command supports the \fB\fC\-n/\-\-dryrun\fR and \fB\fC\-y/\-\-confirm\fR options described
above.
.PP
\fB\fCmanta\-adm alarm config verify [\-\-unconfigure]\fR
.PP
Behaves exactly like \fB\fCmanta\-adm alarm config update \-\-dryrun\fR\&.
.PP
\fB\fCmanta\-adm alarm details ALARM_ID...\fR
.PP
Prints detailed information about any number of alarms.  The detailed
information includes the time the alarm was opened, the last time an event was
associated with this alarm, the total number of events associated with the
alarm, the affected components, and information about the severity, automated
response, and suggested actions for this issue.
.PP
\fB\fCmanta\-adm alarm faults ALARM_ID...\fR
.PP
Prints detailed information about the faults associated with any number of
alarms.  Each fault represents a particular probe failure.  The specific
information provided depends on the alarm.  If the alarm related to a failed
health check command, then the exit status, terminating signal, stdout, and
stderr of the command are provided.  If the alarm relates to an error log entry,
the contents of the log entry are provided.  There can be many faults associated
with a single alarm.
.PP
\fB\fCmanta\-adm alarm list [\-H] [\-o FIELD...] [\-\-state=STATE]\fR
.PP
Lists alarms in tabular form.  \fB\fCSTATE\fR controls which alarms are listed, which
may be any of "open", "closed", "all", or "recent".  The default is "open".
.PP
See also the \fB\fCmanta\-adm alarm show\fR command.
.PP
\fB\fCmanta\-adm alarm maint create CREATE_OPTIONS\fR
.PP
Creates (schedules) an Amon maintenance window, which is a period of time and a
scope for which alarm notifications are suspended.  Maintenance windows have a
start time, an end time, and an operator\-provided notes field (typically used to
reference a ticket number in some other system).  By default, maintenance
windows affect all notifications for an account (and so Manta maintenance
windows affect all Manta\-related notifications), but they can be scoped to a
specific set of probes, probe groups, or machines.
.PP
During maintenance windows, Amon continues to execute all probe checks and it
continues to open new alarms for failing probe checks.  However, faults created
during a maintenance window that are within the scope of that window are
reported as "maintenance faults", and such faults do not trigger notifications.
.PP
As an example, suppose an operator creates a maintenance window for the period
today between 0200Z and 0400Z scoped to machine "lb7".  At 0214Z, Amon detects a
failure for a "log\-scan" probe on machine "lb7" that would normally open a new
alarm and send notifications.  The alarm is opened as usual.  Because the event
happened within the maintenance window's time period and within its scope
(namely, machine "lb7"), a new maintenance fault is created, not a regular
fault, and no notifications are sent out.  But the alarm remains open until an
operator closes it.  A probe check failure for "lb7" after 0400Z would result in
a normal fault being created for the same alarm, and notifications would be
sent.  Similarly, a probe check failure at 0300Z for a different machine would
result in notifications being sent, even if the resulting fault would be
attached to the same alarm (e.g., because the "lb7" probe and this new probe are
in the same probe group).
.PP
The following three option\-arguments are always required:
.TP
\fB\fC\-\-start START_TIME\fR
Specifies the start time of the maintenance window.  \fB\fCSTART_TIME\fR should be an
ISO 8601 timestamp, or else the special string \fB\fCnow\fR, which means that the
window should begin immediately.
.TP
\fB\fC\-\-end END_TIME\fR
Specifies the end time of the maintenance window.  \fB\fCEND_TIME\fR should be an ISO
8601 timestamp, and it must be later than the specified start time.
.TP
\fB\fC\-\-notes NOTES\fR
Provides arbitrary notes to be recorded with the window.  This is intended for
operators to reference tickets or other identifiers in other systems.  The
system ignores the contents of this field except to report it back via the
other subcommands.
.PP
You may also specify:
.TP
\fB\fC\-\-machine MACHINE_UUID, \-\-probe PROBE_UUID, \-\-probegroup GROUP_UUID\fR
Limits the scope of the maintenance window so that it only affects the
specified machines, probes, or probe groups.  You can specify any one of these
options multiple times (e.g., to specify multiple machines), but you cannot
mix these options together.  The values are only validated for basic syntax.
They are not validated against the set of deployed machines, probes, or probe
groups.
.PP
Note that Amon automatically deletes maintenance windows whose end time has
passed.  This tool does not allow you to create maintenance windows whose end
time is in the past.
.PP
Example: create an alarm for the period between 0200Z and 0400Z on July 17,
2017 associated with ticket \fB\fCCM\-123\fR
.PP
.RS
.nf
# manta\-adm alarm maint create \-\-start=2017\-07\-17T02:00:00Z \\
    \-\-end=2017\-07\-17T04:00:00Z \-\-notes "CM\-123"
.fi
.RE
.PP
\fB\fCmanta\-adm alarm maint delete WIN_ID...\fR
.PP
Deletes (cancels) the maintenance windows with identifiers \fB\fCWIN_ID...\fR\&.  The
windows will no longer show up in the \fB\fCmanta\-adm alarm maint list\fR or \fB\fCmanta\-adm
alarm maint show\fR output, and Amon will resume sending notifications for events
that would have fallen within the window's time period and scope.
.PP
\fB\fCWIN_ID\fR is Amon's integer identifier for the window.  You can retrieve this
from the \fB\fCmanta\-adm alarm maint list\fR or \fB\fCmanta\-adm alarm maint show\fR commands.
.PP
This command attempts to separately delete each of the specified windows.  If it
fails to delete any of them (e.g., because they're not valid window identifiers
or because of a transient problem with Amon), it may still have deleted others.
.PP
\fB\fCmanta\-adm alarm maint list [\-H] [\-o FIELD...]\fR
.PP
Lists basic information about outstanding maintenance windows.  This command is
intended when you want tabular output or specific fields.  See the \fB\fCmanta\-adm
alarm maint show\fR command for a more useful human\-readable summary.
.PP
\fB\fCmanta\-adm alarm maint show\fR
.PP
Summarizes each outstanding maintenance window.  This is intended for human
operators, not programmatic tools.  The output format may change in future
versions.
.PP
\fB\fCmanta\-adm alarm metadata events\fR
.PP
List the names for all of the events known to this version of \fB\fCmanta\-adm\fR\&.  Each
event corresponds to a distinct kind of problem.  For details about each one,
see \fB\fCmanta\-adm alarm metadata ka\fR\&.  The list of events comes from metadata
bundled with the \fB\fCmanta\-adm\fR tool.
.PP
\fB\fCmanta\-adm alarm metadata ka [EVENT_NAME...]\fR
.PP
Print out knowledge articles about each of the specified events.  This
information comes from metadata bundled with the \fB\fCmanta\-adm\fR tool.  If no events
are specified, prints out knowledge articles about all events.
.PP
Knowledge articles include information about the severity of the problem, the
impact, the automated response, and the suggested action.
.PP
\fB\fCmanta\-adm alarm notify on|off ALARM_ID...\fR
.PP
Enable or disable notifications for the specified alarms.  Notifications are
generally configured through Amon, which supports both email and XMPP
notification for new alarms and new events on existing, open alarms.  This
command controls whether notifications are enabled for the specified alarms.
.PP
\fB\fCmanta\-adm alarm show\fR
.PP
Summarize open alarms.  For each alarm, use the \fB\fCmanta\-adm alarm details\fR
subcommand to view more information about it.
.SS "cn" subcommand
.PP
\fB\fCmanta\-adm cn [\-l LOG_FILE] [\-H] [\-o FIELD...] [\-n] [\-s] [CN_FILTER]\fR
.PP
The \fB\fCmanta\-adm cn\fR subcommand is used to list SDC compute nodes being used in
the current Manta deployment in the current datacenter.  The default output is a
table with one row per compute node.  See above for information on the \fB\fC\-l\fR,
\fB\fC\-H\fR, and \fB\fC\-o\fR options.
.TP
\fB\fC\-n, \-\-oneachnode\fR
Instead of printing a table, emit a comma\-separated list of matching
hostnames, suitable for use with 
.BR sdc-oneachnode (1)'s 
\fB\fC\-n\fR option.  See also
.BR manta-oneach (1).
.TP
\fB\fC\-s, \-\-storage\-only\fR
Show only compute nodes with "storage" zones on them.
.PP
The optional \fB\fCCN_FILTER\fR string can be used to provide any substring of a
compute node's hostname, server uuid, administrative IP address, compute id, or
storage ids.  All matching compute nodes will be reported.
.PP
Available fields for the \fB\fC\-o/\-\-columns\fR option include "server_uuid", "host",
"dc" (the datacenter name), "admin_ip", "ram", "compute_id", "storage_ids",
and "kind" (which is either "storage" or "other").
.PP
Example: list basic info about all Manta CNs in this DC:
.PP
.RS
.nf
# manta\-adm cn
.fi
.RE
.PP
Example: list info about Manta CN with server uuid matching 7432ffc8:
.PP
.RS
.nf
# manta\-adm cn 7432ffc8
.fi
.RE
.PP
Example: list only storage nodes:
.PP
.RS
.nf
# manta\-adm cn \-s
.fi
.RE
.PP
Example: list only the hostnames (and omit the header):
.PP
.RS
.nf
# manta\-adm cn \-H \-o host
.fi
.RE
.PP
Example: list hostnames in form suitable for "sdc\-oneachnode \-n":
.PP
.RS
.nf
# manta\-adm cn \-n
.fi
.RE
.PP
Example: list storage CNs with their associated storage id (used in object
metadata) and compute ids (vestigial):
.PP
.RS
.nf
# manta\-adm cn \-o host,admin_ip,compute_id,storage_ids storage
.fi
.RE
.SS "genconfig" subcommand
.PP
\fB\fCmanta\-adm genconfig "lab" | "coal"\fR
.PP
\fB\fCmanta\-adm genconfig [\-\-directory=DIR] \-\-from\-file=FILE\fR
.PP
The \fB\fCmanta\-adm genconfig\fR subcommand generates a JSON configuration file
suitable for use with \fB\fCmanta\-adm update\fR\&.  The images used for each service are
the images configured in SAPI, which are generally the last images downloaded by
.BR manta-init (1), 
so this command is sometimes used as a shortcut for identifying
the latest images that have been fetched for each service.
.PP
When the first argument is \fB\fC"coal"\fR, the command produces a configuration
suitable for a small VM\-in\-a\-laptop deployment.  The configuration is always
emitted to stdout.
.PP
When the first argument is \fB\fC"lab"\fR, the command produces a configuration
suitable for a larger single\-server install.  The configuration is always
emitted to stdout.
.PP
The \fB\fC\-\-from\-file=FILE\fR form can be used to generate a configuration suitable for
a much larger, production\-style deployment.  \fB\fCFILE\fR is a JSON file in the format
specified below that describes the parameters of the deployment, including the
number of metadata shards and the set of availability zones, racks, and servers.
This form attempts to create a deployment that will survive failures of any
component, server, rack, or availability zone as long as sufficient servers,
racks, and availability zones are included in the input file.  Availability zone
and rack information can be omitted from the file, in which case the tool will
generate a configuration ignoring rack\-level and AZ\-level considerations.  This
tool uses a number of heuristics, and the output should be verified.
.PP
By default, the generated configuration is emitted to stdout.  With the
\fB\fC\-\-directory\fR option, the configuration will be written to files in the
specified directory named by availability zone.  This option must be used if the
servers in \fB\fCFILE\fR span more than one availability zone.
.PP
The input JSON file \fB\fCFILE\fR should contain a single object with properties:
.TP
\fB\fCnshards\fR (positive integer)
the number of database shards to create.
.TP
\fB\fCservers\fR (array of objects)
the list of servers available for deployment
.PP
Each element of \fB\fCservers\fR is an object with properties:
.TP
\fB\fCtype\fR (string: either \fB\fC"metadata"\fR or \fB\fC"storage"\fR)
identifies this server as a target for metadata services or storage services.
It's not strictly required that Manta services be partitioned in this way, but
this tool requires that because most production deployments use two classes of
hardware for these purposes.
.TP
\fB\fCuuid\fR (string)
the SDC compute node uuid for this server.  This must be unique within the
entire region.
.TP
\fB\fCmemory\fR (positive integer)
gigabytes of memory available on this server.  This is currently only used for
storage servers to determine the appropriate number of compute zones.
.TP
\fB\fCaz\fR (string)
(optional) availability zone.  If the value is omitted from any server, that
server is placed into a default availablity zone.
.TP
\fB\fCrack\fR (string)
(optional) arbitrary identifier for the rack this server is part of.  Racks
often represent fault domains, so the tool uses this information to attempt to
distribute services across racks.  If the value is omitted from any server,
that server is placed into a default rack.
.PP
See the Manta Operator's Guide for a more complete discussion of sizing and
laying out Manta services.
.SS "show" subcommand
.PP
\fB\fCmanta\-adm show [\-l LOG_FILE] [\-a] [\-c] [\-H] [\-o FIELD...] [\-s] SERVICE\fR
.PP
\fB\fCmanta\-adm show [\-l LOG_FILE] [\-js] SERVICE\fR
.PP
The \fB\fCmanta\-adm show\fR subcommand reports information about deployed Manta
component zones.  The default output is a table with one row per deployed zone.
See above for information on the \fB\fC\-l\fR, \fB\fC\-H\fR, and \fB\fC\-o\fR options.
.TP
\fB\fC\-a, \-\-all\fR
Show zones deployed in all datacenters associated with this Manta deployment.
By default, only zones deployed in the current datacenter are shown.  Many
fields for zones deployed in other datacenters will not be available.
.TP
\fB\fC\-c, \-\-bycn\fR
Instead of showing tabular output with one row per zone sorted by service,
group zones by the compute node on which each zone is deployed.  With
\fB\fC\-a/\-\-all\fR, all compute zones in other datacenters are grouped together, since
compute node information is not available for remote datacenters.
.TP
\fB\fC\-s, \-\-summary\fR
Instead of showing tabular output with one row per zone, show tabular output
with one row per group of zones having the same "service", "image", and
"shard" properties (or just "image", for zones to which "shard" does not
logically apply).  The count for each group is also reported.  With
\fB\fC\-j/\-\-json\fR, the same information is presented in JSON form.
.TP
\fB\fC\-j, \-\-json\fR
Instead of the default text\-based output, emit a JSON representation of the
summary information reported with the \fB\fC\-s/\-\-summary\fR command.  This format is
suitable for use with \fB\fCmanta\-adm update\fR\&.  This option cannot be combined with
\fB\fC\-c/\-\-bycn\fR, \fB\fC\-a/\-\-all\fR, \fB\fC\-H/\-\-omit\-header\fR, or \fB\fC\-o/\-\-columns\fR, and it \fImust\fP
be combined with \fB\fC\-s/\-\-summary\fR\&.  (Future versions of this command may support
a different JSON\-based report when \fB\fC\-j/\-\-json\fR is used without
\fB\fC\-s/\-\-summary\fR\&.)  For details on the JSON format, see \fB\fCmanta\-adm update\fR\&.
.PP
If \fB\fCSERVICE\fR is specified, then only zones whose service name is \fB\fCSERVICE\fR will
be reported.
.PP
Available fields for the \fB\fC\-o/\-\-columns\fR option include:
.RS
.IP \(bu 2
\fB\fCdatacenter\fR: the name of the datacenter in which this zone is deployed
.IP \(bu 2
\fB\fCimage\fR: the uuid of the zone's image
.IP \(bu 2
\fB\fCversion\fR: the version of the zone's image
.IP \(bu 2
\fB\fCprimary_ip\fR: the primary IP address for this zone
.IP \(bu 2
\fB\fCservice\fR: the name of the service this zone is part of
.IP \(bu 2
\fB\fCshard\fR: the metadata shard number for this zone.  This is only meaningful
for "moray" and "postgres" zones.
.IP \(bu 2
\fB\fCstorage_id\fR: the internal storage id for this zone.  This is only present
for "storage" zones.
.IP \(bu 2
\fB\fCzonename\fR: the full unique identifier for this zone
.IP \(bu 2
\fB\fCzoneabbr\fR: the first 8 characters of "zonename"
.IP \(bu 2
\fB\fCgz_host\fR: the hostname of the CN on which this zone is deployed
.IP \(bu 2
\fB\fCgz_admin_ip\fR: the primary IP address for the CN on which this zone is
deployed
.IP \(bu 2
\fB\fCcount\fR (summary mode only): the number of zones having the same "service",
"image", and "shard" fields (where meaningful)
.RE
.PP
Note that the "count" field is only meaningful when \fB\fC\-s/\-\-summarize\fR is
specified.  The only other fields that are meaningful when \fB\fC\-s/\-\-sumarize\fR is
specified are "service", "image", "version", and "shard".
.PP
Example: list all Manta zones in the current DC
.PP
.RS
.nf
# manta\-adm show
.fi
.RE
.PP
Example: list zones in the current DC by compute node
.PP
.RS
.nf
# manta\-adm show \-c
.fi
.RE
.PP
Example: summarize Manta zones in the current DC
.PP
.RS
.nf
# manta\-adm show \-s
.fi
.RE
.PP
Example: list all Manta zones in all datacenters (no IP info available)
.PP
.RS
.nf
# manta\-adm show \-a
.fi
.RE
.PP
Example: show only postgres zones in the current datacenter
.PP
.RS
.nf
# manta\-adm show postgres
.fi
.RE
.SS "update" subcommand
.PP
\fB\fCmanta\-adm update [\-l LOG_FILE] [\-n] [\-y] [\-\-no\-reprovision] [\-\-skip\-verify\-channel] FILE [SERVICE]\fR
.PP
The \fB\fCmanta\-adm update\fR command updates a Manta deployment to match the JSON
configuration stored at path \fB\fCFILE\fR\&.  The JSON configuration describes the
precise number of instances that should be running for each version (image) of
each type of service on each server.  The update process will involve some
number of zone deployments, undeployments, and reprovisions.  For example, if
there are 3 "webapi" instances deployed of version "X" on a given server and the
configuration specifies that there should be 1 "webapi" instance at version "Y",
then one of the existing "webapi" instances will be reprovisioned to version "Y"
and the others will be removed.
.PP
The command automatically manages the sequence and concurrency of updates to
minimize impact to a running system.  Because running the command always
compares the current deployment to the one provided in the configuration file,
it is idempotent.  If there are any failures, you can re\-run \fB\fCmanta\-adm update\fR
as needed to bring the system to the desired configuration.
.PP
\fBThis command is primarily intended for use with stateless services.  Extreme
care should be taken when using it with stateful services like "postgres" or
"storage".  See the Manta Operator's Guide for the appropriate procedures for
upgrading all components.\fP
.PP
This command supports the \fB\fC\-l/\-\-log_file\fR, \fB\fC\-n/\-\-dryrun\fR, and \fB\fC\-y/\-\-confirm\fR
options described above, plus:
.TP
\fB\fC\-\-no\-reprovision\fR
When upgrading a zone, always provision a new zone and deprovision the
previous one, rather than reprovisioning the existing one.
.TP
\fB\fC\-\-skip\-verify\-channel\fR
When upgrading, do not verify that the images being provisioned or
reprovisioned are present on the "remote" (usually \[la]https://updates.joyent.com\[ra])
imgapi channel that was set on the headnode using the \fB\fCsdcadm channel\fR
command.
.PP
If \fB\fCSERVICE\fR is specified, then only instances of the named service are
changed.
.PP
The JSON configuration format consists of an object with several levels of
properties:
.nr step0 0 1
.RS
.IP \n+[step0]
Top\-level properties are server uuids.  Everything below a given server uuid
describes instances deployed on that server.
.IP \n+[step0]
The next\-level properties are service names.
.IP \n+[step0]
For services that use shards ("postgres" and "moray"), the next\-level
property names are shard numbers.
.IP \n+[step0]
The next\-level property names are image uuids, which describe the specific
image (version) of zones should be deployed.
.IP \n+[step0]
The values at the leafs are integers describing the number of zones for that
image uuid should be deployed for this service on this server.
.RE
.PP
Here's an example snippet:
.PP
.RS
.nf
{
    "44454c4c\-5700\-1047\-8051\-b3c04f585131": {
        "nameservice": {
            "59ef6322\-6968\-11e5\-987a\-0bd10a3d6e65": 3
        },
        "postgres": {
            "1": {
                "0a8692f6\-6968\-11e5\-a997\-3334c877b2f3": 3
            },
            "2": {
                "0a8692f6\-6968\-11e5\-a997\-3334c877b2f3": 3
            }
        },
        ...
    }
}
.fi
.RE
.PP
This configuration denotes that on the server with uuid
"44454c4c\-5700\-1047\-8051\-b3c04f585131", there should be:
.RS
.IP \(bu 2
three "nameservice" instances using image
"59ef6322\-6968\-11e5\-987a\-0bd10a3d6e65",
.IP \(bu 2
three "postgres" instances in shard 1 using image
"0a8692f6\-6968\-11e5\-a997\-3334c877b2f3", and
.IP \(bu 2
three "postgres" instances in shard 2 using image
"0a8692f6\-6968\-11e5\-a997\-3334c877b2f3".
.RE
.PP
The starting point for an update operation is usually the output of \fB\fCmanta\-adm
show \-sj\fR\&.  From that configuration, you can:
.RS
.IP \(bu 2
scale up or down the number of any component by increasing or decreasing the
counts,
.IP \(bu 2
upgrade all instances of a component by changing the image uuid for it, and
.IP \(bu 2
perform rolling upgrades by adding a second image uuid for a service with
count "1", then updating repeatedly with more instances of the second image
and fewer instances of the first image.
.RE
.PP
subject to the caveats described above for stateful services.
.PP
This tool does not provide an interface for undeploying or upgrading specific
zones by zonename.
.PP
Example: update the current deployment to the configuration in \fB\fCnewconfig.json\fR:
.PP
.RS
.nf
# manta\-adm update newconfig.json
.fi
.RE
.PP
Example: update only "moray" instances to the configuration in \fB\fCnewconfig.json\fR:
.PP
.RS
.nf
# manta\-adm update newconfig.json moray
.fi
.RE
.SS "zk" subcommand
.PP
\fB\fCmanta\-adm zk list [\-l LOG_FILE] [\-H] [\-o FIELD...]\fR
.PP
\fB\fCmanta\-adm zk fixup [\-l LOG_FILE] [\-n] [\-y]\fR
.PP
The \fB\fCmanta\-adm zk\fR subcommand provides subcommands for viewing and repairing the
list of ZooKeeper peers.  The \fB\fCmanta\-adm zk list\fR command reports a tabular view
of the ZooKeeper servers used for the current Manta deployment.  The \fB\fCmanta\-adm
zk fixup\fR command compares the ZooKeeper configuration (defined by the
\fB\fCZK_SERVERS\fR and \fB\fCZK_ID\fR SAPI metadata properties) to the list of deployed
nameservice zones, reports any discrepancies or other issues, and optionally
repairs certain kinds of issues.  If repairs are made, only metadata is changed.
This tool is intended for cases where a ZK server has been undeployed and the
configuration needs to be updated, or where deployment failed and left stale
configuration, or other unusual cases where the configuration does not match the
list of deployed nameservers.
.PP
See above for information about the \fB\fC\-l\fR, \fB\fC\-H\fR, and \fB\fC\-o\fR options for
\fB\fCmanta\-adm zk list\fR\&.  Fields available for use with \fB\fC\-o\fR include "ord" (the
ordinal number of each server), "datacenter", "zoneabbr", "zonename", "ip", and
"port".
.PP
The \fB\fCmanta\-adm zk fixup\fR command supports the \fB\fC\-l/\-\-log_file\fR, \fB\fC\-n/\-\-dryrun\fR,
and \fB\fC\-y/\-\-confirm\fR options described above.
.SH EXIT STATUS
.TP
\fB\fC0\fR
Success
.TP
\fB\fC1\fR
Generic failure.
.TP
\fB\fC2\fR
The command\-line options were not valid.
.SH COPYRIGHT
.PP
Copyright 2019 Joyent, Inc.
.SH SEE ALSO
.PP
.BR json (1), 
Manta Operator's Guide
